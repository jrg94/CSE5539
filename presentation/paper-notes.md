# Presentation Notes

On 4/15, I'll be presenting the following chapter and paper in class:

Goto M. (2006): “Analysis of musical audio signals,” In Wang D.L. & Brown G.J. (eds.):
Computational auditory scene analysis: Principles, algorithms, and applications. IEEE
Press/Wiley, Hoboken NJ, Chapter 8, pp. 251-295.

Rafii Z. and Pardo B. (2013): “REpeating Pattern Extraction Technique (REPET): A simple
method for music/voice separation,” IEEE/ACM Transactions on Audio, Speech, and
Language Processing, vol. 21, pp. 71-82.

Naturally, I'll be using this space to record my notes.

## [Analysis of Musical Audio Signals][1]

This chapter is broken up into sections, so I'll summarize them separately.

### 8.1: Introduction

The introduction covers the idea that people are capable of comprehending music
without necessarily separate all the individuals sounds. In other words, they
understand the mixture of sounds. Obviously, we'd like to be able to replicate
that behavior in a computer.

## [REpeating Pattern Extraction Technique (REPET)][2]

At a high level, REPET is a tool for extracting repeating pattern audio from
a musical track. It can be used to separate vocals from a musical track.

[1]: #
[2]: http://music.cs.northwestern.edu/publications/Rafii-Pardo%20-%20REpeating%20Pattern%20Extraction%20Technique%20(REPET)%20A%20Simple%20Method%20for%20Music-Voice%20Separation%20-%20TALSP%202013.pdf
